{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b317f61",
   "metadata": {},
   "source": [
    "### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4374117c",
   "metadata": {},
   "source": [
    "Missing values refer to absence of a particular value or info for a variable or observation reason such as incomplete data collection, data entry errors, or technical issues during data processing.\n",
    "\n",
    "It's essential to handle such missing values as they affect the accuracy and validity of analysis and accuracy of ML models, which lead to biased or incorrect results, difficult to draw reliable conclusions \n",
    "\n",
    "Algo affected by missing values:\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Support Vector Machines (SVM)\n",
    "- Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ee46a",
   "metadata": {},
   "source": [
    "### Q2: List down techniques used to handle missing data. Give an example of each with python code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc6c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5db8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Deleting rows containing missing values\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98eda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Deleting columns which contains missing values\n",
    "df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e513431",
   "metadata": {},
   "source": [
    "## 3 Imputation\n",
    "- Mean Imputation \n",
    "- Median Imputation \n",
    "- Mode Imputation \n",
    "- Random Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01256d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Mean Imputation \n",
    "df['age_mean'] = df['age'].fillna(df['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Median imputation \n",
    "df['age_median'] = df['age'].fillna(df['age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Mode Imputation\n",
    "df['age_mode'] = df['age'].fillna(df['age'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144efdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Random value Imputation\n",
    "df['age_mean'] = df['age'].fillna(23) # any random value filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948a020",
   "metadata": {},
   "source": [
    "### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea3cf2",
   "metadata": {},
   "source": [
    "Imbalance data refers to a situation where representation of dataset is not equal. This means that one or more classes have significantly fewer samples than the others. Imbalanced data is common in many real-world applications such as fraud detection\n",
    "\n",
    "Most ML algo designed to assume that dataset are balanced & will behave poorly if imbalanced data applied, \n",
    "\n",
    "If Imbalanced data isn't handled it can lead to several problems, includes: \n",
    "- Poor Performance\n",
    "- Biased Models \n",
    "- Overfitting\n",
    "\n",
    "#### To handle this several techniques could be used\n",
    "- Resampling\n",
    "- Cost-sensitive learning\n",
    "- Algo modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084fb09",
   "metadata": {},
   "source": [
    "### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950af0b9",
   "metadata": {},
   "source": [
    "#### Upsampling involves increasing the number of samples in the minority class to match with the majority class. Done by replicating existing samples in the minority class, or by generating new synthetic samples.\n",
    "##### example, consider a dataset with 1000 samples of Class A and 100 samples of Class B. If we upsample Class B to 1000 samples using SMOTE, we can create a balanced dataset with 1000 samples of each class.\n",
    "\n",
    "#### DownSampling:\n",
    "##### This involves reducing the no. of samples in the majority class to match with no.s of minority class. Done randomly or using more sophisticated techniques, such as clustering or instance selection. \n",
    "\n",
    "##### For example, consider a dataset with 1000 samples of Class A and 100 samples of Class B. If we downsample Class A to 100 samples, we can create a balanced dataset with 100 samples of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1a239c",
   "metadata": {},
   "source": [
    "### Q5: What is data Augmentation? Explain SMOTE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b1ec16",
   "metadata": {},
   "source": [
    "#### Artificially expand the size of a training set by creating modified data from the existing one is said to Data Automation. Used to prevent overfitting, or the initial dataset is too small to train on, or for better model performace\n",
    "\n",
    "#### DA good for enhancing the model’s performance.\n",
    "\n",
    "#### Popular DA technique SMOTE (Synthetic Minority Over-sampling Technique). SMOTE used to address imbalace where minority class is significantly small. SMOTE generates synthetic examples of the minority class by interpolating between existing instance\n",
    "\n",
    "#### Basic idea of SMOTE is similar to k-nearest neighbor simply finding points nearest to existing Specifically, SMOTE selects a random point along the line segment connecting the minority example and its nearest neighbor and adds this point as a new datapoint.\n",
    "\n",
    "#### SMOTE can be very effective in improving the performance of machine learning models on imbalanced datasets. By creating synthetic examples of the minority class, SMOTE can help to address the problem of class imbalance and ensure that the model is better able to generalize to new examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73f522",
   "metadata": {},
   "source": [
    "### Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09550d9d",
   "metadata": {},
   "source": [
    "#### Outliers are nothing but the points that lie outside the overall distribution of the dataset. if not treated, can cause serious problems in statistical analyses.\n",
    "\n",
    "### Types of Outliers\n",
    "\n",
    "##### Outliers are generally classified into two types: Univariate and Multivariate.\n",
    "\n",
    "##### 1. Univariate Outliers – These outliers are found in the distribution of values in a single feature space.\n",
    "\n",
    "##### 2. Multivariate Outliers – These outliers are found in the distribution of values in a n-dimensional space (n-features).\n",
    "\n",
    "#### Problems due to outliers\n",
    "\n",
    "##### 1. Skewed data distribution\n",
    "\n",
    "##### 2. Misleading statistical measures\n",
    "\n",
    "##### 3. Biased machine learning models\n",
    "\n",
    "##### 4. Reduced model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f05819",
   "metadata": {},
   "source": [
    "### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c94fd",
   "metadata": {},
   "source": [
    "### There are several techniques that can be used to handle missing data in customer data analysis:\n",
    "\n",
    "1. Deletion\n",
    "2. Imputation\n",
    "3. Regression\n",
    "4. Multiple imputation\n",
    "5. Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d263df",
   "metadata": {},
   "source": [
    "### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25276966",
   "metadata": {},
   "source": [
    "### When dealing with missing data, there are several strategies to determine if the missing data is missing at random or if there is a pattern to the missing data. Here are some of the most commonly used methods:\n",
    "\n",
    "1. Analyze missing patterns: Can be done by analyzing, plotting, distinguishing them related to missingness\n",
    "\n",
    "2. Correlation analysis: Find correlation of missing vlaues with other field\n",
    "\n",
    "3. Imputation and analysis: Impute the missing values using various techniques and compare the results.\n",
    "\n",
    "4. Expert knowledge: Sometimes expert knowledge can help determining if the missing data is missing at random or not.\n",
    "\n",
    "5. Statistical tests: Performing statistical tests Like MCAR test to determine if the missing data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e9378c",
   "metadata": {},
   "source": [
    "### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd54392",
   "metadata": {},
   "source": [
    "### Strategies to evaluate performance of ML model on an imbalanced dataset:\n",
    "\n",
    "1. Confusion matrix: this summarizes the performance of a classification model. It shows the true positive, false positive, true negative, and false negative rates. Not great for imbalanced datasets\n",
    "\n",
    "2. Resampling techniques: Used to balance the dataset. Upsampling and Downsampling could be done, upsampling leads to overfitting and downsampling leads to underfitting of the model\n",
    "\n",
    "3. Ensemble methods: This combine multiple models to improve their performance. Training multiple models on different subsets of the dataset and averaging their predictions. \n",
    "\n",
    "4. Cost-sensitive learning: This involves assigning different costs to different types of errors. In the case of an imbalanced dataset, misclassifying a minority class example as a majority class example may be more costly than the opposite. By assigning different costs to different types of errors, the model can be trained to minimize the overall cost of errors rather than just the number of errors.\n",
    "\n",
    "5. Domain knowledge: used to improve the model's performance on an imbalanced dataset. For example, if the dataset contains demographic information, you can use this information to stratify the dataset and ensure that both classes are represented equally in each stratum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787fd347",
   "metadata": {},
   "source": [
    "### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1240d",
   "metadata": {},
   "source": [
    "### Several methods to balance an unbalanced dataset and down-sample the majority class.:\n",
    "\n",
    "1. Random under-sampling: removing instances from the majority class until the dataset is balanced.\n",
    "\n",
    "2. Cluster-based under-sampling: clustering the majority class instances and then selecting representative instances from each cluster.\n",
    "\n",
    "3. Tomek Links: This identifies pairs of instances from different classes that are close to each other, and removes the majority class instance from each pair. By doing this, the Tomek Links method creates a clearer separation between the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b241722",
   "metadata": {},
   "source": [
    "### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on an project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2d393",
   "metadata": {},
   "source": [
    "### Having unbalanced data with rare occurance of event we could employ several technique to balance the dataset and up-sample the minority class:\n",
    "1. Random over-sampling: This involves randomly duplicating instances from the minority class until the dataset is balanced. \n",
    "\n",
    "2. Synthetic minority over-sampling technique (SMOTE): This method involves creating synthetic instances of the minority class by interpolating between existing instances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
