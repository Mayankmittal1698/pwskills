{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400b5ac4",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0332d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Web scrapping also known as web data Extraction which formally known as process of obtaning & structuring data from \n",
    "web using intelligent automation. It can be used to retrieve hundreds, millions or billions of data points from internet\n",
    "effortlessly. \n",
    "\n",
    "Basicaly of two Parts: \n",
    "web Crawling (in this browses internet to index & search for content by following links like google crawler bot which categorizes webs)\n",
    "Web scrapper (In this Data extraction from a webpage or specially designed APIs which gave us access to scrap limited or specific data)\n",
    "\n",
    "\n",
    "Web Scraping used in soo many field whether it could be history price comparision , sentiment analysis like people what now a days buying or eating \n",
    "extracting info from social media regarding pattern behaviour of it's user which can be used for promotion, political agenda setting and categorization of\n",
    "images, webpages\n",
    "\n",
    "Areas where Web scraping used: \n",
    "collecting historical data for trend prediction and future analysis \n",
    "collecting customers or client information from websites and social media so which help marketers and salespeople\n",
    "currency exchange rates, job boards, weather forcasting are some other usecase\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75636a",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c914d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There could be several method involved in we scraping which includes manual selection and automated crawling \n",
    "web pages using pre-programmed scraping applications.\n",
    "HTTP request to extract data from the websites all this by doing task automated \n",
    "DOM parsing, text pattern matching and computer vision web page analysi are some other method used in web scraping\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e9337",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaef4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files.\n",
    "It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner.\n",
    "Beautiful Soup helps you pull particular content from a webpage, remove the HTML markup, and save the information. \n",
    "It is a tool for web scraping that helps you clean up and parse the documents\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43c1c1",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbdc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Flask is used in web scraping projects because it is a lightweight framework that is easy to learn and use. \n",
    "It is also more explicit than Djangoâ€™s framework, which makes it easier to understand and implement a simple web application.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92576345",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In our AWS project we used two AWS service named as: \n",
    "- code pipeline \n",
    "- Bean Stalk \n",
    "\n",
    "Code Pipeline: It is a continues  delivery service we can use to model, visualize, and automate the steps required\n",
    "to release your software. We can quickly model and configure the different stages of a software release process. \n",
    "CodePipeline automates the steps required to release your software changes continuously.\n",
    "\n",
    "Bean stalk or AWS Elastic Beanstalk is a conputer service that makes it easier for developer to quickly deploy and manage\n",
    "applciation that they uploaded to AWS cloud \n",
    "beanstalk handle the configuration and provision for them by reducing management complexity without restricting choice or control\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
